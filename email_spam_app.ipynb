{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter.ttk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfile\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    file = open(r'models\\LRC_model.pkl', 'rb')\n",
    "    LRC= pickle.load(file)   \n",
    "    file = open(r'models\\SVC_model.pkl', 'rb')\n",
    "    SVC= pickle.load(file) \n",
    "    file = open(r'models\\DTC_model.pkl', 'rb')\n",
    "    DTC= pickle.load(file) \n",
    "    file = open(r'models\\KNN_model.pkl', 'rb')\n",
    "    KNN= pickle.load(file) \n",
    "    file = open(r'models\\RFC_model.pkl', 'rb')\n",
    "    RFC= pickle.load(file)\n",
    "    file = open(r'models\\NBC_model.pkl', 'rb')\n",
    "    NBC= pickle.load(file) \n",
    "    return LRC,SVC,DTC,KNN,RFC,NBC\n",
    "LRC,SVC,DTC,KNN,RFC,NBC =load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(email):\n",
    "    email=re.sub(\"^Subject: \",\"\",email) #remove (Subject: )\n",
    "    email=re.sub(\"[^a-zA-Z]\",\" \",email) #remove special characters\n",
    "    #email=re.sub(\"\\s\\w\\s\",\"\",email) # remove s in 's and t in 't (like book's cover or he can't)\n",
    "    email=re.sub(\"^\\s+\",\"\",email) #remove leading space\n",
    "    email=re.sub(\"\\s+$\",\"\",email) #remove trailing space\n",
    "    email=re.sub(\"\\s+\",\" \",email) #remove extra spaces between words\n",
    "    email=email.lower()           #lowercase every word\n",
    "\n",
    "    return email\n",
    "def tokenize(email):\n",
    "     list_of_words=nltk.word_tokenize(email)\n",
    "     return list_of_words\n",
    "def remove_stopwords(email):\n",
    "   clean_words=[]\n",
    "   list_of_words=tokenize(email)\n",
    "\n",
    "   for word in list_of_words:\n",
    "      if(word not in stopwords.words('english')):\n",
    "         clean_words.append(word)\n",
    "\n",
    "   email=' '.join(clean_words) #convert list to string with seperator between every element (' ')\n",
    "\n",
    "   return email\n",
    "def lemmatize_email(email):\n",
    "    lemmatized_words=[]\n",
    "\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    for word in tokenize(email):\n",
    "        new_word=lemmatizer.lemmatize(word)\n",
    "        lemmatized_words.append(new_word)\n",
    "    email=' '.join(lemmatized_words)\n",
    "    return email "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_email(email):\n",
    "    preprocessed_email=preprocess(email)\n",
    "    preprocessed_email=remove_stopwords(preprocessed_email)\n",
    "    preprocessed_email=lemmatize_email(preprocessed_email)\n",
    "    file = open('vectorizer.pkl', 'rb')\n",
    "    vectorizer = pickle.load(file)\n",
    "    # Fit and transform text data\n",
    "    tfidf_matrix = vectorizer.transform([preprocessed_email])\n",
    "    vector=tfidf_matrix.toarray()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(encoded_label):\n",
    "    label=None\n",
    "    if encoded_label[0][0]==0 and encoded_label[0][1]==1:\n",
    "        label='spam'\n",
    "    elif encoded_label[0][0]==1 and encoded_label[0][1]==0:\n",
    "        label='ham'\n",
    "    return label       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=Tk()\n",
    "root.config(background='gray')\n",
    "root.title('Email Spam Detection')\n",
    "root.geometry('800x500+250+100')\n",
    "main_fw=Frame(root,bg='gray')\n",
    "model_lbl=Label(main_fw,width=10,height=1,bg='gray',pady=5,text='Model',font=30)\n",
    "model_lbl.grid(column=1,row=1)\n",
    "model_box=tkinter.ttk.Combobox(main_fw,width=27,height=30)\n",
    "model_box['values']=('Auto','Logistic Regression','SVM','Decision Tree','KNN','Random Forest','Naive Bayes')\n",
    "model_box.grid(column=1, row=2)\n",
    "model_box.current()\n",
    "email_lbl=Label(main_fw,width=10,height=1,bg='gray',pady=5,text='Email',font=30)\n",
    "email_lbl.grid(column=1,row=3)\n",
    "email_box = Text(main_fw, width=60, height=10)\n",
    "email_box.grid(column=1, row=4,pady=5)\n",
    "def detect_email():\n",
    "    label=None\n",
    "    result_lbl=Label(main_fw,width=10,height=1,bg='gray',pady=5,text='Result',font=30)\n",
    "    result_lbl.grid(column=1,row=10)\n",
    "    value_lbl=Label(main_fw,width=10,height=1,bg='black',fg='white',pady=5,text=label,font=30)\n",
    "    value_lbl.grid(column=1,row=11) \n",
    "    value_lbl.config(text=label) \n",
    "    email=email_box.get(1.0,\"end-1c\")\n",
    "    email=str(email)\n",
    "    preprocessed_email=preprocess_email(email)\n",
    "    model=model_box.get()\n",
    "    if model=='Auto' or model=='SVM':\n",
    "        pred=SVC.predict(preprocessed_email)\n",
    "        label=get_label(pred)\n",
    "    elif model=='Logistic Regression':\n",
    "        pred=LRC.predict(preprocessed_email)\n",
    "        label=get_label(pred)\n",
    "    elif model=='Decision Tree':\n",
    "        pred=DTC.predict(preprocessed_email)\n",
    "        label=get_label(pred)\n",
    "    elif model=='KNN':\n",
    "        pred=KNN.predict(preprocessed_email)\n",
    "        label=get_label(pred)\n",
    "    elif model=='Random Forest':\n",
    "        pred=RFC.predict(preprocessed_email)\n",
    "        label=get_label(pred)\n",
    "    elif model=='Naive Bayes':\n",
    "        pred=NBC.predict(preprocessed_email)\n",
    "        label=get_label(pred)\n",
    "    if label=='ham':\n",
    "        value_lbl.config(text=label,bg='green')\n",
    "    elif label=='spam':\n",
    "        value_lbl.config(text=label,bg='red')    \n",
    "\n",
    "predict_btn=Button(main_fw,text='Predict',width=30,height=2,\n",
    "                    command=detect_email,bg='black',fg='white',font=30,pady=5)\n",
    "predict_btn.grid(column=1,row=8,pady=20)\n",
    "\n",
    "\n",
    "\n",
    "main_fw.pack()\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
